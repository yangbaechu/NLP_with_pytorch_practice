{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nltk 튜토리얼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]\n"
     ]
    }
   ],
   "source": [
    "##nltk 다운로드 잘 되었는지 확인하기\n",
    "from nltk.corpus import brown\n",
    "print(brown.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'fileinput' has no attribute 'fileInput'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-382844c213cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mfileinput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'fileinput' has no attribute 'fileInput'"
     ]
    }
   ],
   "source": [
    "##책에서 나온 방법 -> fileinput 모듈 사용방법 몰라서 실패\n",
    "import sys, fileinput, re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fileinput.fileInput('data.txt')\n",
    "    for line in f:\n",
    "        if line.strip() != \"\":\n",
    "            line = re.sub(r'([a-z])\\.([A-Z])', r'\\1. \\2', line.strip())\n",
    "\n",
    "            sentences = sent_tokenize(line.strip())\n",
    "\n",
    "            for s in sentences:\n",
    "                if s != \"\":\n",
    "                    sys.stdout.write(s + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kss를 이용한 문장 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서울 뉴시스 장윤희 기자 카카오가 외부 저널리즘 전문가들로 구성된 자문기구 미디어자문위원회 를 9일 발족했다.\n",
      "신설된 미디어자문위원회는 카카오의 이용자 맞춤형 콘텐츠 추천 시스템인 루빅스 RUBICS 알고리즘이 다양한 정보를 신속하게 전달하면서 미디어의 중립적인 역할을 하도록 논의한다.\n",
      "루빅스는 이용자의 콘텐츠 소비 성향을 분석해 이용자가 선호하는 뉴스를 다음과 카카오톡 채널 메인 화면에 띄우는 알고리즘이다.\n",
      "예를 들어 평소 스포츠 뉴스를 많이 본 이용자는 포털 다음에 접속할 때 야구나 축구 뉴스를 메인 화면에서 먼저 접할 수 있다.\n",
      "카카오는 향후 미디어자문위원회 의견을 수렴해 루빅스 알고리즘이 미디어 산업 발전과 더불어 이용자의 뉴스 콘텐츠 소비 다양성에 이바지할 수 있도록 발전시켜 나간다는 방침이다.\n",
      "미디어자문위원회 위원장으로는 이재경 이화여대 커뮤니케이션·미디어학부 교수가 위촉됐다.\n",
      "기타 위원으로는 김민정 한국외대 미디어커뮤니케이션학과 교수 김장현 성균관대 인터랙션사이언스학과 교수 박재영 고려대 미디어학부 교수 이준웅 서울대 언론정보학과 교수 정재민 KAIST 정보미디어 경영대학원 교수 등 총 6명이다.\n",
      "임선영 카카오 미디어 총괄 이사는 다음커뮤니케이션에서 2014년까지 운영하다\n",
      "다음 카카오 합병으로 잠시 중단된 외부 옴부즈맨 기구 열린이용자위원회 가 이번에 미디어자문위원회 란 상시 운영기구로 재출범하게 됐다 며 20대 총선을 앞두고 다음뉴스의 공정성과 다양성을 확대하는데 미디어 전문가들의 참여가 큰 역할을 해줄 것 이라고 기대했다.\n",
      "미디어자문위원회는 이달 말 정기 회의를 열고 본격적으로 활동을 시작한다.\n",
      "카카오는 회의록과 활동 내용을 글쓰기 플랫폼 브런치 를 통해 투명하게 공개할 계획이다.\n"
     ]
    }
   ],
   "source": [
    "import kss\n",
    "text  = '서울 뉴시스 장윤희 기자 카카오가 외부 저널리즘 전문가들로 구성된 자문기구 미디어자문위원회 를 9일 발족했다. 신설된 미디어자문위원회는 카카오의 이용자 맞춤형 콘텐츠 추천 시스템인 루빅스 RUBICS 알고리즘이 다양한 정보를 신속하게 전달하면서 미디어의 중립적인 역할을 하도록 논의한다. 루빅스는 이용자의 콘텐츠 소비 성향을 분석해 이용자가 선호하는 뉴스를 다음과 카카오톡 채널 메인 화면에 띄우는 알고리즘이다. 예를 들어 평소 스포츠 뉴스를 많이 본 이용자는 포털 다음에 접속할 때 야구나 축구 뉴스를 메인 화면에서 먼저 접할 수 있다. 카카오는 향후 미디어자문위원회 의견을 수렴해 루빅스 알고리즘이 미디어 산업 발전과 더불어 이용자의 뉴스 콘텐츠 소비 다양성에 이바지할 수 있도록 발전시켜 나간다는 방침이다. 미디어자문위원회 위원장으로는 이재경 이화여대 커뮤니케이션·미디어학부 교수가 위촉됐다. 기타 위원으로는 김민정 한국외대 미디어커뮤니케이션학과 교수 김장현 성균관대 인터랙션사이언스학과 교수 박재영 고려대 미디어학부 교수 이준웅 서울대 언론정보학과 교수 정재민 KAIST 정보미디어 경영대학원 교수 등 총 6명이다. 임선영 카카오 미디어 총괄 이사는 다음커뮤니케이션에서 2014년까지 운영하다 다음 카카오 합병으로 잠시 중단된 외부 옴부즈맨 기구 열린이용자위원회 가 이번에 미디어자문위원회 란 상시 운영기구로 재출범하게 됐다 며 20대 총선을 앞두고 다음뉴스의 공정성과 다양성을 확대하는데 미디어 전문가들의 참여가 큰 역할을 해줄 것 이라고 기대했다. 미디어자문위원회는 이달 말 정기 회의를 열고 본격적으로 활동을 시작한다. 카카오는 회의록과 활동 내용을 글쓰기 플랫폼 브런치 를 통해 투명하게 공개할 계획이다.'\n",
    "for line in kss.split_sentences(text):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## konlpy를 이용한 형태소 단위의 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "꼬꼬마 형태소 분석기 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['한국어', 'NLP', '에서', '형태소', '분석기', '를', '사용', '하', 'ㄴ다는', '것', '은', '단어', '토큰', '화가', '아니', '라', '정확히', '는', '형태소', '단위', '로', '형태소', '토큰', '화', '를', '수행', '하', '게', '되', 'ㅁ', '을', '뜻하', 'ㅂ니다']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma()\n",
    "##형태소 추출\n",
    "print(kkma.morphs(\"한국어 NLP에서 형태소 분석기를 사용한다는 것은 단어 토큰화가 아니라 정확히는 형태소 단위로 형태소 토큰화를 수행하게 됨을 뜻합니다\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('한국어', 'NNG'), ('NLP', 'OL'), ('에서', 'JKM'), ('형태소', 'NNG'), ('분석기', 'NNG'), ('를', 'JKO'), ('사용', 'NNG'), ('하', 'XSV'), ('ㄴ다는', 'ETD'), ('것', 'NNB'), ('은', 'JX'), ('단어', 'NNG'), ('토큰', 'NNG'), ('화가', 'NNG'), ('아니', 'VCN'), ('라', 'ECD'), ('정확히', 'MAG'), ('는', 'JX'), ('형태소', 'NNG'), ('단위', 'NNG'), ('로', 'JKM'), ('형태소', 'NNG'), ('토큰', 'NNG'), ('화', 'NNG'), ('를', 'JKO'), ('수행', 'NNG'), ('하', 'XSV'), ('게', 'ECD'), ('되', 'VV'), ('ㅁ', 'ETN'), ('을', 'JKO'), ('뜻하', 'VV'), ('ㅂ니다', 'EFN')]\n"
     ]
    }
   ],
   "source": [
    "##품사 태깅\n",
    "print(kkma.pos(\"한국어 NLP에서 형태소 분석기를 사용한다는 것은 단어 토큰화가 아니라 정확히는 형태소 단위로 형태소 토큰화를 수행하게 됨을 뜻합니다\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##명사 추출\n",
    "print(kkma.nois(\"한국어 NLP에서 형태소 분석기를 사용한다는 것은 단어 토큰화가 아니라 정확히는 형태소 단위로 형태소 토큰화를 수행하게 됨을 뜻합니다\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okt 형태소 분석기 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['한국어', 'NLP', '에서', '형태소', '분석', '기를', '사용', '한다는', '것', '은', '단어', '토큰', '화가', '아니라', '정확히는', '형태소', '단위', '로', '형태소', '토큰', '화', '를', '수행', '하게', '됨을', '뜻', '합니다']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "##형태소 추출\n",
    "print(okt.morphs(\"한국어 NLP에서 형태소 분석기를 사용한다는 것은 단어 토큰화가 아니라 정확히는 형태소 단위로 형태소 토큰화를 수행하게 됨을 뜻합니다\"), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('한국어', 'Noun'), ('NLP', 'Alpha'), ('에서', 'Josa'), ('형태소', 'Noun'), ('분석', 'Noun'), ('기를', 'Verb'), ('사용', 'Noun'), ('한다는', 'Modifier'), ('것', 'Noun'), ('은', 'Josa'), ('단어', 'Noun'), ('토큰', 'Noun'), ('화가', 'Noun'), ('아니라', 'Adjective'), ('정확히는', 'Adjective'), ('형태소', 'Noun'), ('단위', 'Noun'), ('로', 'Josa'), ('형태소', 'Noun'), ('토큰', 'Noun'), ('화', 'Suffix'), ('를', 'Josa'), ('수행', 'Noun'), ('하게', 'Verb'), ('됨을', 'Verb'), ('뜻', 'Noun'), ('합니다', 'Verb')]\n"
     ]
    }
   ],
   "source": [
    "##품사 태깅\n",
    "print(okt.pos(\"한국어 NLP에서 형태소 분석기를 사용한다는 것은 단어 토큰화가 아니라 정확히는 형태소 단위로 형태소 토큰화를 수행하게 됨을 뜻합니다\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['한국어', '형태소', '분석', '사용', '것', '단어', '토큰', '화가', '형태소', '단위', '형태소', '토큰', '수행', '뜻']\n"
     ]
    }
   ],
   "source": [
    "##명사 추출\n",
    "print(okt.nouns(\"한국어 NLP에서 형태소 분석기를 사용한다는 것은 단어 토큰화가 아니라 정확히는 형태소 단위로 형태소 토큰화를 수행하게 됨을 뜻합니다\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
